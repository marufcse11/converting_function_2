{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6cnn21KX0GcVCkfis2C8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marufcse11/converting_function_2/blob/main/converting_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "-_oB1n3CHyWF",
        "outputId": "7d855834-e126-48e8-8a5d-c5abf256fa45"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fdaec15e176d>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'df_dynamic_dic'"
          ]
        }
      ],
      "source": [
        "from Models.Regression.regression_functions import train_model, split_dataset, get_train_model_results\n",
        "from Models.Regression import constant\n",
        "\n",
        "from Models.mlflow_utils import support_mlflow\n",
        "import mlflow as mlflow\n",
        "from mlflow import log_param\n",
        "from Models.utils import mlflow_init_spark_exe\n",
        "from pycaret.regression import *\n",
        "\n",
        "metadata = {\n",
        "    #/Users/maruf/Documents/GitHub/exec-service-python/Models/NewFunctions/ModelTraining/Regression\n",
        "    'pythonModule': \"Models.NewFunctions.ModelTraining.Regression.converting_function\",\n",
        "    'spark': False,\n",
        "    'inputs': {\n",
        "        \"target\": {'type': 'string'},\n",
        "        \"train_size\": {'type': 'string'},\n",
        "        \"estimator_name\": {'type': 'string'},\n",
        "        \"regression_train_input_data\": {'type': 'pandas-dataframe'}\n",
        "    },\n",
        "    'outputs': {\n",
        "        \"regression_train_output_data\": {\n",
        "            'type': 'spark-dataframe',\n",
        "            'preferredBackend': 'hive'\n",
        "        },\n",
        "        \"regression_train_metrics_viz\": {\n",
        "            'type': 'pandas-dataframe',\n",
        "            'preferredBackend': 'artifact-store'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# description of  inputs and outputs\n",
        "\"\"\"\n",
        "inputs:\n",
        "    target: the field name that the regression model is trying to predict\n",
        "    train_size: this parameter is used to specify the proportion of data that will be used for training a regression model\n",
        "    estimator_name: this is the regression algorithm used to train a regression model\n",
        "    regression_train_input_data: this is a collection of data that is used to train, test, and evaluate a regression model \n",
        "outputs:\n",
        "    regression_train_output_data: this is the output data from the regression model\n",
        "    regression_train_metrics_viz: this shows the metrics in terms of the performance of the regression model\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def run(inputs, context):\n",
        "    \"\"\"\n",
        "    This function is used to train a multiple model\n",
        "    \"\"\"\n",
        "    try:\n",
        "        #mlflow_init_spark_exe(inputs, context)\n",
        "\n",
        "        # read dataset\n",
        "        dataset = inputs['regression_train_input_data']\n",
        "        # dataset = dataset.toPandas()\n",
        "\n",
        "        # check params\n",
        "        if not ('target' in inputs):\n",
        "            raise ValueError('Missing target column')\n",
        "        else:\n",
        "            target = inputs['target']\n",
        "            #exp_name = setup(data = df_dic,target)\n",
        "        # assign default value for optional variables\n",
        "        if not ('train_size' in inputs):\n",
        "            train_size = constant.REGRESSION_TRAIN_SIZE\n",
        "        else:\n",
        "            train_size = float(inputs['train_size'])\n",
        "        if not ('round_to' in inputs):\n",
        "            round_to = constant.REGRESSION_ROUND_TO\n",
        "        else:\n",
        "            round_to = int(inputs['round_to'])\n",
        "\n",
        "        if not ('fold' in inputs):\n",
        "            fold = constant.REGRESSION_FOLD\n",
        "        else:\n",
        "            fold = int(inputs['fold'])\n",
        "\n",
        "        if not ('estimator_name' in inputs):\n",
        "            estimator_name = constant.REGRESSION_ESTIMATOR_NAME\n",
        "        else:\n",
        "            estimator_name = inputs['estimator_name']\n",
        "\n",
        "        def converting_function(df_dynamic_dic):\n",
        "            df_dynamic = df_dynamic_dic.copy()\n",
        "            for c in df_dynamic_dic.columns:\n",
        "                #print(\"out c value = \",c)\n",
        "    \n",
        "                df_dynamic_dic = df_dynamic_dic.sort_values([c])\n",
        "                test_str = df_dynamic_dic[c].values[0]\n",
        "                if isinstance(test_str, str) == True:\n",
        "                    if df_dynamic_dic[c].dtype == object:\n",
        "                        df_dynamic_dic[c] = df_dynamic_dic[c].str.capitalize()\n",
        "                        #print(\"c value = \",c)\n",
        "                        df_dynamic_dic[c].fillna('0', inplace=True)\n",
        "                        d = Counter(df_dynamic_dic[c].astype(str))           \n",
        "                        keys = list(d)\n",
        "                        award_df = pd.DataFrame.from_dict(d, orient='index')\n",
        "                        award_df = award_df.reset_index()\n",
        "                        award_df.columns = ['Value', 'Count']\n",
        "                        award_df = award_df.sort_values(['Count'])\n",
        "                        award_df.insert(0, 'Code', range(0, 0 + len(award_df)))\n",
        "                        award_df_1 = dict(zip(award_df['Value'], award_df['Code']))\n",
        "                        df_dynamic[c] = df_dynamic_dic[c].map(award_df_1)\n",
        "                        len(set(keys)), len(d)\n",
        "                        sfile = '/content/drive/My Drive/Ass_1/Dictonary.xlsx'\n",
        "                        mode = 'a' if os.path.exists(sfile) else 'w'\n",
        "                        mode2 = 'replace' if os.path.exists(sfile) else None              \n",
        "                        with pd.ExcelWriter(sfile, engine='openpyxl', mode=mode, if_sheet_exists=mode2) as writer:\n",
        "                            award_df.to_excel(writer, sheet_name = c, index= False)\n",
        "            return df_dynamic\n",
        "\n",
        "        df_dic = converting_function(dataset)\n",
        "\n",
        "        exp_name = setup(data = df_dic,  target)\n",
        "        best_model = compare_models()\n",
        "        plot_model(best_model)\n",
        "        evaluate_model(best_model)\n",
        "        \n",
        "        \n",
        "        # # split data\n",
        "        # split_dataset(\n",
        "        #     training_data=df,\n",
        "        #     target=target,\n",
        "        #     train_size=train_size\n",
        "        # )\n",
        "        # # train model and get metrics and best trained model\n",
        "        # metrics, trained_model = train_model(\n",
        "        #     estimator_name=estimator_name,\n",
        "        #     round_to=round_to,\n",
        "        #     fold=fold,\n",
        "        # )\n",
        "        # metrics, _, model_params_df, predictions = get_train_model_results()\n",
        "\n",
        "        # mlflow tracking components (e.g. logging parameters, metrics, trained models)\n",
        "        # TODO (Owner: Felix)\n",
        "\n",
        "        outputs = {\n",
        "            'regression_train_output_data': predictions,\n",
        "            'regression_train_metrics_viz': metrics\n",
        "        }\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    except Exception as inst:\n",
        "        raise inst\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ]
    }
  ]
}